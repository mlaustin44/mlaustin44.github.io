<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Setting up a Kubernetes Cluster from Scatch with Proxmox, Debian and Ansible - Part 1 (VMs) | Matt Austin</title>
    <meta name="generator" content="VuePress 1.5.2">
    
    <meta name="description" content="
One of the main things I wanted to be able to use my home server for was self hosting applications.  Since Kubernetes has become the standard framework for enterprise container orchestration, and I u ...">
    <link rel="preload" href="/assets/css/0.styles.ef48967c.css" as="style"><link rel="preload" href="/assets/js/app.719779a0.js" as="script"><link rel="preload" href="/assets/js/6.5a5d3722.js" as="script"><link rel="preload" href="/assets/js/3.0200f067.js" as="script"><link rel="preload" href="/assets/js/9.076c7963.js" as="script"><link rel="prefetch" href="/assets/js/10.ad42f919.js"><link rel="prefetch" href="/assets/js/11.5f2113f1.js"><link rel="prefetch" href="/assets/js/12.cbe1e5dd.js"><link rel="prefetch" href="/assets/js/13.71ad5dd4.js"><link rel="prefetch" href="/assets/js/14.1d0ed4df.js"><link rel="prefetch" href="/assets/js/15.46172771.js"><link rel="prefetch" href="/assets/js/16.b495c123.js"><link rel="prefetch" href="/assets/js/17.5bee3966.js"><link rel="prefetch" href="/assets/js/18.bb37b752.js"><link rel="prefetch" href="/assets/js/4.1e0a0c14.js"><link rel="prefetch" href="/assets/js/5.dfc964d0.js"><link rel="prefetch" href="/assets/js/7.a11674cb.js"><link rel="prefetch" href="/assets/js/8.bd5481f9.js"><link rel="prefetch" href="/assets/js/vuejs-paginate.fd7b906a.js">
    <link rel="stylesheet" href="/assets/css/0.styles.ef48967c.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="vuepress-theme-blog__global-layout"><section id="header-wrapper"><header id="header"><div class="header-wrapper"><div class="title"><a href="/" class="nav-link home-link">Matt Austin </a></div> <div class="header-right-wrap"><ul class="nav"><li class="nav-item"><a href="/" class="nav-link">Blog</a></li><li class="nav-item"><a href="/tag/" class="nav-link">Tags</a></li></ul> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></div></header></section> <div id="mobile-header"><div class="mobile-header-bar"><div class="mobile-header-title"><a href="/" class="nav-link mobile-home-link">Matt Austin </a> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></div> <div class="mobile-menu-wrapper"><hr class="menu-divider"> <ul class="mobile-nav"><li class="mobile-nav-item"><a href="/" class="nav-link">Blog</a></li><li class="mobile-nav-item"><a href="/tag/" class="nav-link">Tags</a></li> <li class="mobile-nav-item"><!----></li></ul></div></div></div> <div class="content-wrapper"><div id="vuepress-theme-blog__post-layout"><article itemscope="itemscope" itemtype="https://schema.org/BlogPosting" class="vuepress-blog-theme-content"><header><h1 itemprop="name headline" class="post-title">
        Setting up a Kubernetes Cluster from Scatch with Proxmox, Debian and Ansible - Part 1 (VMs)
      </h1> <div class="post-meta"><div itemprop="publisher author" itemtype="http://schema.org/Person" itemscope="itemscope" class="post-meta-author"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-navigation"><polygon points="3 11 22 2 13 21 11 13 3 11"></polygon></svg> <span itemprop="name">mlaustin</span> <!----></div> <div class="post-meta-date"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg> <time pubdate itemprop="datePublished" datetime="2020-08-10T00:00:00.000Z">
      Sun Aug 09 2020
    </time></div> <ul itemprop="keywords" class="post-meta-tags"><li class="post-tag" data-v-42ccfcd5><a href="/tag/proxmox" data-v-42ccfcd5><span data-v-42ccfcd5>proxmox</span></a></li><li class="post-tag" data-v-42ccfcd5><a href="/tag/kubernetes" data-v-42ccfcd5><span data-v-42ccfcd5>kubernetes</span></a></li><li class="post-tag" data-v-42ccfcd5><a href="/tag/ansible" data-v-42ccfcd5><span data-v-42ccfcd5>ansible</span></a></li><li class="post-tag" data-v-42ccfcd5><a href="/tag/debian" data-v-42ccfcd5><span data-v-42ccfcd5>debian</span></a></li><li class="post-tag" data-v-42ccfcd5><a href="/tag/docker" data-v-42ccfcd5><span data-v-42ccfcd5>docker</span></a></li></ul></div></header> <div itemprop="articleBody" class="content__default"><h2 id="introduction"><a href="#introduction" class="header-anchor">#</a> Introduction</h2> <p>One of the main things I wanted to be able to use my home server for was self hosting applications.  Since Kubernetes has become the standard framework for enterprise container orchestration, and I use it frequently in projects at work, I thought that the home server was a great oppurtunity to leverage Kubernetes as my container orchestration framework while getting to learn more about its inner workings and management by deploying my own cluster.</p> <p>I also wanted to use an automation technology to deploy everything on my home server using an 'infrastructure as code' solution.  This would accomplish 2 things for me: I'd get to learn a new technology of interest to me, and I'd have all of the steps to deploy and configure my home server captured as source-controlled code so that when I had to come fix something after not touching it for months I'd be able to quickly see how it had been configured and deployed</p> <p>All of my commited code to build these VMs is on <a href="https://github.com/mlaustin44/server_setup/tree/master/k8s-debian" target="_blank" rel="noopener noreferrer">my Github<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</p> <p>I think this will part 1 of a 5 part series on my home lab Kubernetes cluster:</p> <ol><li>Deploying VMs</li> <li>Installing base software and configs</li> <li>Bootstrapping a kubernetes cluster</li> <li>Configuring MetalLB for load balancing</li> <li>Configuring ingress-nginx for ingress routing</li></ol> <h2 id="basic-plan"><a href="#basic-plan" class="header-anchor">#</a> Basic Plan</h2> <p>I'm going to run a 4 node cluster (1 master, 3 workers) as Debian VMs on my <a href="/_posts/2020-08-04-hp-proliant-dl360p-gen8-home-server.html">Proxmox host server</a>.  My original plan was to use Fedora CoreOS, which is a stripped down container-only Linux OS which was bought by Red Hat recently.  I spent quite a bit of time getting a CoreOS deployment working but I eventually got stuck on getting the VMs to configure correctly on first boot using the unique Ignition tool that CoreOS uses instead of cloud-init.  I decided to shelve that plan as I didn't actually need CoreOS for anything - I just thought it would be a lightweight, interesting base for my cluster.  The most recent versions of my attempts is <a href="https://github.com/mlaustin44/server_setup/tree/master/k8s-coreos" target="_blank" rel="noopener noreferrer">commited to my github<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> in case anyone is curious.</p> <p>The Kubernetes cluster is going to run on a seperate VLAN from my main network (main is 192.168.1.0/24, k8s will be on 192.168.40.0/24).</p> <h2 id="ansible-intro"><a href="#ansible-intro" class="header-anchor">#</a> Ansible Intro</h2> <p>Ansible is a great tool for automating setup and configuration tasks - basically anything that you could do through shell commands or scripts, Ansible has a much cleaner easier syntax configured with YAML files.  I'm certain I'm not using Ansible to the full extent of what it's capable of, but I'll try to teach what I learned as I go through my process in the hope that it offers a good intro to someone.</p> <p>Ansible works by using a series of tasks which combine into a playbook.  Each task is a single action which needs to be taken, expressed in YAML form.  Each set of tasks can be applied to local or remote computers.</p> <h2 id="network-pre-configuration"><a href="#network-pre-configuration" class="header-anchor">#</a> Network Pre-Configuration</h2> <p>My server has a 4 port NIC, so I connected a second port to my switch.  That allows one port which is primary used for management traffic with no VLAN tagging, and one used for VMs which allows VLAN tagging.  I just created a second bridge adapter in Proxmox and made sure that 'VLAN Aware' was active:
<img src="/assets/img/proxmoxbridge.b0a13d74.png" alt="New Network Bridge"></p> <p>This way, any VM ethernet adapters configued to use VLAN tagging will have the 802.1q tags applied at the Proxmox bridge.</p> <p>I also configured my router and switch to recognize the new VLAN and allow traffic on the switch port the second server interface as attached to.</p> <h2 id="building-vms"><a href="#building-vms" class="header-anchor">#</a> Building VMs</h2> <h3 id="configuring-ansible-inventory"><a href="#configuring-ansible-inventory" class="header-anchor">#</a> Configuring Ansible Inventory</h3> <p>Ansible uses an 'inventory.ini' file to tell it which computers to execute various tasks on.  Since I know what my final setup is going to look like with static IPs, I generated a new SSH key to use just for my VMs and then configured this Ansible inventory:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">[</span>proxmox_server<span class="token punctuation">]</span>
192.168.1.240

<span class="token punctuation">[</span>k8s_master<span class="token punctuation">]</span>
192.168.40.10

<span class="token punctuation">[</span>k8s_nodes<span class="token punctuation">]</span>
192.168.40.100
192.168.40.101
192.168.40.102

<span class="token punctuation">[</span>proxmox_server<span class="token punctuation">:</span>vars<span class="token punctuation">]</span>
ansible_user='root'
ansible_shh_private_key_file='~/.ssh/server_key'
ansible_ssh_common_args='<span class="token punctuation">-</span>o ServerAliveInterval=5 <span class="token punctuation">-</span>o StrictHostKeyChecking=no'

<span class="token punctuation">[</span>k8s_master<span class="token punctuation">:</span>vars<span class="token punctuation">]</span>
ansible_user='debian'
ansible_shh_private_key_file='~/.ssh/server_key'
ansible_ssh_common_args='<span class="token punctuation">-</span>o ServerAliveInterval=5 <span class="token punctuation">-</span>o StrictHostKeyChecking=no'

<span class="token punctuation">[</span>k8s_nodes<span class="token punctuation">:</span>vars<span class="token punctuation">]</span>
ansible_user='debian'
ansible_shh_private_key_file='~/.ssh/server_key'
ansible_ssh_common_args='<span class="token punctuation">-</span>o ServerAliveInterval=5 <span class="token punctuation">-</span>o StrictHostKeyChecking=no'
</code></pre></div><p>This configures three groups of hosts - one for my proxmox server, one for my k8s master node, and one for the remaining k8s worker nodes.  These groups are what can be targeted by tasks.</p> <p>Since these are all remote machines that need to be SSH'd to, I also configured the user accounts, SSH keys, and SSH parameters for each connection.</p> <h3 id="basic-setup"><a href="#basic-setup" class="header-anchor">#</a> Basic Setup</h3> <p>Then I created a new .yml file for a playbook to deploy the VMs with a basic configuiration.</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token punctuation">-</span> <span class="token key atrule">hosts</span><span class="token punctuation">:</span> proxmox_server
  <span class="token key atrule">gather_facts</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>
  <span class="token key atrule">vars</span><span class="token punctuation">:</span>
    <span class="token key atrule">stg</span><span class="token punctuation">:</span> <span class="token string">&quot;vmstorage&quot;</span>
    <span class="token key atrule">nodes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token punctuation">{</span><span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token string">&quot;4010&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;stormfather&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">'2'</span><span class="token punctuation">,</span> <span class="token key atrule">mem</span><span class="token punctuation">:</span> <span class="token string">'8192'</span><span class="token punctuation">,</span> <span class="token key atrule">ip</span><span class="token punctuation">:</span> <span class="token string">'192.168.40.10'</span><span class="token punctuation">}</span>
      <span class="token punctuation">-</span> <span class="token punctuation">{</span><span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token string">&quot;40100&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;windrunner&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">'1'</span><span class="token punctuation">,</span> <span class="token key atrule">mem</span><span class="token punctuation">:</span> <span class="token string">'4096'</span><span class="token punctuation">,</span> <span class="token key atrule">ip</span><span class="token punctuation">:</span> <span class="token string">'192.168.40.100'</span><span class="token punctuation">}</span>
      <span class="token punctuation">-</span> <span class="token punctuation">{</span><span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token string">&quot;40101&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;lightweaver&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">'1'</span><span class="token punctuation">,</span> <span class="token key atrule">mem</span><span class="token punctuation">:</span> <span class="token string">'4096'</span><span class="token punctuation">,</span> <span class="token key atrule">ip</span><span class="token punctuation">:</span> <span class="token string">'192.168.40.101'</span><span class="token punctuation">}</span>
      <span class="token punctuation">-</span> <span class="token punctuation">{</span><span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token string">&quot;40102&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> <span class="token string">&quot;edgedancer&quot;</span><span class="token punctuation">,</span> <span class="token key atrule">cpu</span><span class="token punctuation">:</span> <span class="token string">'1'</span><span class="token punctuation">,</span> <span class="token key atrule">mem</span><span class="token punctuation">:</span> <span class="token string">'4096'</span><span class="token punctuation">,</span> <span class="token key atrule">ip</span><span class="token punctuation">:</span> <span class="token string">'192.168.40.102'</span><span class="token punctuation">}</span>
    <span class="token key atrule">net_bridge</span><span class="token punctuation">:</span> vmbr1
    <span class="token key atrule">net_gw</span><span class="token punctuation">:</span> <span class="token string">&quot;192.168.40.1&quot;</span>
    <span class="token key atrule">net_dns</span><span class="token punctuation">:</span> <span class="token string">&quot;192.168.1.1&quot;</span>
    <span class="token key atrule">vlan_tag</span><span class="token punctuation">:</span> <span class="token number">40</span>
</code></pre></div><p>To break this down:</p> <ul><li>The hosts field tells ansible which group of hosts (from the inventory) this will be run on.  Since I'm going to be creating and configuring VMs, Ansible needs to run directly on the Proxmox server.</li> <li>Gather_facts sets whether Ansible should run a report on the remote systems first.  It can get a huge amount of information about the remote systems, but since I didn't need any of that, it's disabled</li> <li>The vars section lets you define variables which can be used in the playbook tasks.  I used this to store a list of the VMs I'm going to provision along with some basic individual configurations, as well as the overall networking configuration.</li></ul> <h3 id="create-the-proxmox-resource-pool"><a href="#create-the-proxmox-resource-pool" class="header-anchor">#</a> Create the Proxmox resource pool</h3> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Create resource pool for k8s VMs
  <span class="token key atrule">shell</span><span class="token punctuation">:</span> pvesh create /pools <span class="token punctuation">-</span>poolid &quot;kubernetes&quot;
  <span class="token key atrule">ignore_errors</span><span class="token punctuation">:</span> yes
</code></pre></div><p>The first task is creating a Proxmox resource pool to group the VMs.  The Ansible 'shell' module just runs whatever follows as a shell command.  I set ignore_errors because during the development of these scripts I redeployed the VMs frequently without deleting the resource pool in between each run, so I needed Ansible to ignore the error the the resource pool already existed.</p> <h3 id="download-the-debian-vm-image"><a href="#download-the-debian-vm-image" class="header-anchor">#</a> Download the Debian VM image</h3> <p>Since I'm using QEMU KVM VMs for the nodes, I wanted to use a qcow2 image, which is a preinstalled, preconfigured VM disk image for running in a KVM.  This avoids needing to automate any installation or setup tasks and lets the VMs start with very basic installed and configured Debian.</p> <p>Download the qcow2 image from Debian's openstack server:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Download Ubuntu Server 20.04 kvm image
  <span class="token key atrule">get_url</span><span class="token punctuation">:</span>
    <span class="token key atrule">url</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//cdimage.debian.org/cdimage/openstack/current<span class="token punctuation">-</span>10/debian<span class="token punctuation">-</span>10<span class="token punctuation">-</span>openstack<span class="token punctuation">-</span>amd64.qcow2
    <span class="token key atrule">dest</span><span class="token punctuation">:</span> /tmp/debian<span class="token punctuation">-</span>10<span class="token punctuation">-</span>openstack<span class="token punctuation">-</span>amd64.qcow2
</code></pre></div><p>Get_url just does a basic HTTP download like wget.  This is working remotely on the Proxmox server, so it's downloading that /tmp/ directory, not my local computer.</p> <h3 id="copy-local-ssh-key-to-the-proxmox-server"><a href="#copy-local-ssh-key-to-the-proxmox-server" class="header-anchor">#</a> Copy local SSH key to the Proxmox server</h3> <p>Need to get my SSH key on to the Proxmox server in order to configure the Kubernetes nodes with it.  By default, the Debian qcow2 image (like most qcow2 images for Linux distros) has a single user account with no password configured, so there's no way to SSH into the VM without configuring an SSH key, which we'll do later via cloud init.</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Copy SSH key to proxmox server
  <span class="token key atrule">copy</span><span class="token punctuation">:</span>
    <span class="token key atrule">src</span><span class="token punctuation">:</span> /home/mlaustin/.ssh/server_key.pub
    <span class="token key atrule">dest</span><span class="token punctuation">:</span> /tmp/key.pub
</code></pre></div><p>Copy, by contrast, copies files from your local machine to the remote machine by default.  If you want it to copy within the remote machine, you need to use 'remote_src: true'.</p> <h3 id="create-the-vms"><a href="#create-the-vms" class="header-anchor">#</a> Create the VMs</h3> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Create the k8s vms
  <span class="token key atrule">shell</span><span class="token punctuation">:</span> <span class="token punctuation">&gt;</span><span class="token scalar string">
    qm create {{ item.id }}
    --pool kubernetes
    --ostype l26
    --name {{ item.name }}
    --description &quot;Kubernetes Node VM&quot;
    --agent 1
    --cores {{ item.cpu }}
    --memory {{ item.mem }}
    --net0 virtio,bridge={{ net_bridge }},tag={{ vlan_tag }}
    --ipconfig0 gw={{ net_gw }},ip={{ item.ip }}/24
    --sshkeys /tmp/key.pub</span>
  <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ nodes }}&quot;</span>
</code></pre></div><p>There's quite a few things going on in this one.  'qm create' is the <a href="https://pve.proxmox.com/pve-docs/qm.1.html" target="_blank" rel="noopener noreferrer">Proxmox command to create a new qEMU virtual machine<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.  I'm going to break this into Ansible specific stuff about the task and Proxmox specific stuff about the shell command.</p> <h4 id="the-ansible-stuff"><a href="#the-ansible-stuff" class="header-anchor">#</a> The Ansible Stuff</h4> <p>Ansible uses the handlebar ( {{}} ) syntax for templating variables into text.  Anywhere a value appears surrounded by double curly brackets, Ansible with substitute in a variable.  It's convention to include a leading and trailing space around the contents of the bracketed variable.  You don't need qoutes or anything with the templating syntax - UNLESS you use it immediately following a YAML colon, in which case you need to use qoutes to show that you are using an Ansible string template, rather than a YAML object.</p> <p>There are two ways to multi-line shell commands in Ansible - '|' and '&gt;'.</p> <ul><li>'&gt;' means that all the lines are combined into one before running.  It's equivilant to this in a shell script:<div class="language-bash extra-class"><pre class="language-bash"><code>qm create <span class="token number">4010</span> <span class="token punctuation">\</span>
--pool kubernetes <span class="token punctuation">\</span>
--ostype l26 <span class="token punctuation">\</span>
<span class="token punctuation">..</span><span class="token punctuation">..</span>
</code></pre></div></li> <li>'|' runs each line as a seperate command.  Generally in Ansible you dont want to combine too many things in one task because your visibility into results and errors is decreased because too many things are happening, but occasionally it makes more sense to combine dependent tasks.  The following commands are equivilant between Ansible and Bash:
<h5 id="ansible"><a href="#ansible" class="header-anchor">#</a> Ansible</h5> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token key atrule">shell</span><span class="token punctuation">:</span> <span class="token punctuation">|</span><span class="token scalar string">
  apt-get update
  apt-get install vim</span>
</code></pre></div><h5 id="bash"><a href="#bash" class="header-anchor">#</a> Bash</h5> <div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">apt-get</span> update
<span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">vim</span>
</code></pre></div><div class="language-bash extra-class"><pre class="language-bash"><code><span class="token function">apt-get</span> update <span class="token operator">&amp;&amp;</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">vim</span>
</code></pre></div></li></ul> <p>'with_items' is the Ansible directive to loop over a list.  It's equivilant to <code>for item in items:</code> in Python or <code>for (auto &amp; item : vector) {...}</code> in C++.  The variable name used inside the loop is 'item', and access to fields within the object are 'item.field'.  So this loop will run 4 times - once per item in the nodes list created in the configuration.  Recall the we need the qoutes around the template!  We want to pass in a raw list here, as with_items can also be used like:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token key atrule">with_items</span><span class="token punctuation">:</span>
  <span class="token punctuation">-</span> first_item
  <span class="token punctuation">-</span> second_item
  <span class="token punctuation">-</span> third_item
</code></pre></div><h4 id="the-proxmox-stuff"><a href="#the-proxmox-stuff" class="header-anchor">#</a> The Proxmox Stuff</h4> <p>Each time the loop runs, we'll run 'qm create' to create one virtual machine in Proxmox.  This will be a partially configured virtual machine at this step.</p> <p>For any configuration that is occuring <em>within</em> the VM (networking config, SSH keys, etc) Proxmox uses <a href="https://cloudinit.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">cloud-init<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, which packages the configuration for the VM to consume into files and mounts them to the VM as a drive on first boot.  The qcow2 Debian image we are using is configured to automatically look for and use cloud init, so the values configured in the following commands are picked up by the VM at first boot and used to set the configuration.</p> <p>Some of the arguments used to create the VM are pretty self explanatory, while others are more involved. I'll just cover the involved ones here:</p> <ul><li>ostype: the type of guest operating system.  These are described in the <a href="https://pve.proxmox.com/wiki/Qemu/KVM_Virtual_Machines" target="_blank" rel="noopener noreferrer">Proxmox manual<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> (search for 'ostype: &lt;' to find the section).  l26 means a Linux guest, Kernel version &gt;2.6.</li> <li>agent: whether the <a href="https://pve.proxmox.com/wiki/Qemu-guest-agent" target="_blank" rel="noopener noreferrer">Qemu guest agent<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> is enabled.  The guest agent is a daemon that gets installed inside the guest to allow the host to pass in ACPI commands to reset, power off, etc.</li> <li>net0: the 0 means this is the first network device (eth0 on Linux).  You can configure as many network devices as the guest would support using --net1, --net2...--netN.  The value of this command configures the <em>hardware</em> portion of the network device, while the --ipconfig argument configures the <em>networking</em> configuration of the network device.  The values passed into the network adpater config must be comma seperated without spaces.
<ul><li>The first argument is the device type to attach.  Qemu is capable of emulating a variety of real-world physical network interface devices, but emulation of hardware adds extra overhead the virtualization.  <a href="https://wiki.libvirt.org/page/Virtio" target="_blank" rel="noopener noreferrer">virtio<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> is a set of standardized virtualization native device drivers which are included in most major operating systems.  This allows the host to use a very efficent interface for devices without needing to worry about driver compatibility.  Debian (like every major linux distro) has virtio drivers included, so we'll use the virtual device instead of trying to emulate a hardware device.</li> <li>Bridge allows us to specify which bridge adpater the machine should be connected to.  Recall that hypervisor VM bridges are software network switches, so this is just selecting which switch we are plugging our VM into.</li> <li>Tag sets the 802.1q VLAN tagging.  This argument is only needed if the VMs will be running on a VLAN, otherwise it can be removed.</li> <li>There are a variety of additional values which can be configured, see the Proxmox documentation for details (search 'net[n]:' on <a href="https://pve.proxmox.com/wiki/Qemu/KVM_Virtual_Machines" target="_blank" rel="noopener noreferrer">this page<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>)</li></ul></li> <li>ipconfig0: sets the IP configuration for a network adapter with the matching number (net0&lt;-&gt;ipconfig0, etc).  This configuration is passed into the VM as described above.  You can pass the string 'dhcp' to use DHCP, otherwise an IP address (with CIDR) and gateway need to be provided.</li> <li>sshkeys: location of the public key file for the SSH key to be used.  One important note - you can only pass in a single --sshkeys argument.  I ran into trouble trying to configure multiple SSH keys at the same time as only the last key provided would take.  The documentation says 'one key per line, OpenSSH format'.  It doesn't mean to pass multiple lines to the command, but rather to pass in a file with multiple SSH keys in it, one per line, like an authorized_hosts file.  In my case, I just pass in the key file which was copied to the Proxmox host in an earlier step.</li></ul> <h3 id="import-the-debian-disk-to-each-vm"><a href="#import-the-debian-disk-to-each-vm" class="header-anchor">#</a> Import the Debian disk to each VM</h3> <p>As mentioned above, the qcow2 disk images are virtual hard drives ready to restore on to a VM.  In Proxmox 'qm importdisk' does exactly what it says:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Import qcow2 image as a disk to each VM
  <span class="token key atrule">shell</span><span class="token punctuation">:</span> qm importdisk <span class="token punctuation">{</span><span class="token punctuation">{</span> item.id <span class="token punctuation">}</span><span class="token punctuation">}</span> /tmp/debian<span class="token punctuation">-</span>10<span class="token punctuation">-</span>openstack<span class="token punctuation">-</span>amd64.qcow2 <span class="token punctuation">{</span><span class="token punctuation">{</span> stg <span class="token punctuation">}</span><span class="token punctuation">}</span>
  <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ nodes }}&quot;</span>
</code></pre></div><p>This step takes a while as each compressed qcow2 image needs to be expanded to its original size.</p> <h3 id="configure-the-imported-disks"><a href="#configure-the-imported-disks" class="header-anchor">#</a> Configure the imported disks</h3> <p>The disks are now imported to the VMs, but they're not configured to actually mount to them.  We can now go back to the VMs and configure some remaining hardware using 'qm set', which is a general tool that edits any attribute of a VM.</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Configure the VM disk hardware
  <span class="token key atrule">shell</span><span class="token punctuation">:</span> <span class="token punctuation">&gt;</span><span class="token scalar string">
    qm set {{ item.id }}
    --scsihw virtio-scsi-pci
    --scsi0 {{ stg }}:vm-{{ item.id }}-disk-0
    --ide2 &quot;{{ stg }}:cloudinit&quot;
    --serial0 /dev/tty0
    --boot c
    --bootdisk scsi0</span>
  <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ nodes }}&quot;</span>
</code></pre></div><p>Quick run through these arguments:</p> <ul><li>scsihw: sets the model of the SCSI controller configured on the VM.  As always, I'm going with the virtio device where possible and configuring it as a PCI card SCSI adapter</li> <li>scsi0: this sets the disk to attach to the VM as the first (well, zero-th) hard drive.  When I ran 'qm importdisk' in the prior step it imported the disk and named it according to a standard scheme which we use to attach it to the VM here.</li> <li>ide2: mounts the cloud-init disk as a CD drive on the VM so it can adopt the configuration.  The use of n=2 and the disk name are both <a href="https://pve.proxmox.com/wiki/Cloud-Init_Support" target="_blank" rel="noopener noreferrer">standard in Proxmox<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>serial0: creates a serial device on the VM and configures a passthrough to the host at the specified /dev/tty.  This is also required for cloud-init and is configured per the Proxmox documentation and is required by Openstack images for <a href="https://cloudinit.readthedocs.io/en/latest/topics/datasources/smartos.html" target="_blank" rel="noopener noreferrer">SmartOS Datasource<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li> <li>boot: sets the boot device, where a=floppy, c=HDD, d=CD-ROM, and n=network</li> <li>bootdisk: sets the disk to boot from</li></ul> <h3 id="resize-the-hard-disks"><a href="#resize-the-hard-disks" class="header-anchor">#</a> Resize the hard disks</h3> <p>The qcow2 images had a configured size prior to compression which they will revert to when they're imported.  I want to resize them to 20gb, which can be done with the 'qm resize' command:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Resize VM disks
  <span class="token key atrule">shell</span><span class="token punctuation">:</span> qm resize <span class="token punctuation">{</span><span class="token punctuation">{</span> item.id <span class="token punctuation">}</span><span class="token punctuation">}</span> scsi0 20G
  <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ nodes }}&quot;</span>
</code></pre></div><h3 id="finally-start-the-vms-and-wait-for-them-to-be-available"><a href="#finally-start-the-vms-and-wait-for-them-to-be-available" class="header-anchor">#</a> Finally, start the VMs and wait for them to be available</h3> <p>Pretty straightfoward - Ansible has a wait_for directive which allows you to set a hostname and port and wait until that host is responding on that port.  The default timeout is 300 seconds (5 minutes):</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Start the VMs
  <span class="token key atrule">shell</span><span class="token punctuation">:</span> qm start <span class="token punctuation">{</span><span class="token punctuation">{</span> item.id <span class="token punctuation">}</span><span class="token punctuation">}</span>
  <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ nodes }}&quot;</span>

<span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Wait for VMs to be available
  <span class="token key atrule">wait_for</span><span class="token punctuation">:</span>
    <span class="token key atrule">host</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ item.ip }}&quot;</span>
    <span class="token key atrule">port</span><span class="token punctuation">:</span> <span class="token number">22</span>
    <span class="token key atrule">msg</span><span class="token punctuation">:</span> <span class="token string">&quot;VMs not available after 5 minutes&quot;</span>
  <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ nodes }}&quot;</span>
</code></pre></div><h2 id="run-the-playbook"><a href="#run-the-playbook" class="header-anchor">#</a> Run the playbook</h2> <p>I ran the Ansible playbook with:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>ansible-playbook -i inventory.ini playbooks/deploy_vms.yml
</code></pre></div><p>In order to simplify my workflow once I had more than one playbook to run (since I tried to seperate logical steps into seperate playbooks), I created a site.yml file which automated calling a series of playbooks:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token punctuation">-</span> <span class="token key atrule">import_playbook</span><span class="token punctuation">:</span> playbooks/deploy_vms.yml
<span class="token punctuation">-</span> <span class="token key atrule">import_playbook</span><span class="token punctuation">:</span> playbooks/install_base_software.yml
<span class="token punctuation">-</span> <span class="token key atrule">import_playbook</span><span class="token punctuation">:</span> playbooks/bootstrap_k8s.yml
<span class="token punctuation">-</span> <span class="token key atrule">import_playbook</span><span class="token punctuation">:</span> playbooks/deploy_metallb.yml
<span class="token punctuation">-</span> <span class="token key atrule">import_playbook</span><span class="token punctuation">:</span> playbooks/deploy_nginx_ingress.yml
</code></pre></div><p>I also made myself a handy little counterpart playbook called 'destroy_vms.yml' to clean up my inevitable mistakes before trying again:</p> <div class="language-yaml extra-class"><pre class="language-yaml"><code><span class="token punctuation">---</span>
<span class="token punctuation">-</span> <span class="token key atrule">hosts</span><span class="token punctuation">:</span> proxmox_server
  <span class="token key atrule">gather_facts</span><span class="token punctuation">:</span> <span class="token boolean important">False</span>
  <span class="token key atrule">vars</span><span class="token punctuation">:</span>
    <span class="token key atrule">id_list</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">&quot;4010&quot;</span>
      <span class="token punctuation">-</span> <span class="token string">&quot;40100&quot;</span>
      <span class="token punctuation">-</span> <span class="token string">&quot;40101&quot;</span>
      <span class="token punctuation">-</span> <span class="token string">&quot;40102&quot;</span>

  <span class="token key atrule">tasks</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Forcibly remove the locks
      <span class="token key atrule">shell</span><span class="token punctuation">:</span> rm <span class="token punctuation">-</span>f /var/lock/qemu<span class="token punctuation">-</span>server/lock<span class="token punctuation">-</span><span class="token punctuation">{</span><span class="token punctuation">{</span> item <span class="token punctuation">}</span><span class="token punctuation">}</span>.conf
      <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ id_list }}&quot;</span>

    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Stop VMs
      <span class="token key atrule">shell</span><span class="token punctuation">:</span> qm stop <span class="token punctuation">{</span><span class="token punctuation">{</span> item <span class="token punctuation">}</span><span class="token punctuation">}</span>
      <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ id_list }}&quot;</span>
    
    <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Destroy VMs
      <span class="token key atrule">shell</span><span class="token punctuation">:</span> qm destroy <span class="token punctuation">{</span><span class="token punctuation">{</span> item <span class="token punctuation">}</span><span class="token punctuation">}</span> <span class="token punctuation">-</span><span class="token punctuation">-</span>purge
      <span class="token key atrule">with_items</span><span class="token punctuation">:</span> <span class="token string">&quot;{{ id_list }}&quot;</span>
</code></pre></div><p>My standard command during development was to run:</p> <div class="language-bash extra-class"><pre class="language-bash"><code>ansible-playbook -i inventory.ini playbooks/destroy_vms.yaml <span class="token operator">&amp;&amp;</span> ansible-playbook -i inventory.ini site.yml
</code></pre></div><p>...and then take a quick 5 minute break.</p> <h2 id="next-time"><a href="#next-time" class="header-anchor">#</a> Next Time</h2> <p>We install some software on the VMs!</p> <h2 id="references"><a href="#references" class="header-anchor">#</a> References</h2> <ol><li>https://github.com/zimmertr/Bootstrap-Kubernetes-with-QEMU</li></ol></div> <footer><!----> <hr> <!----></footer></article> <div class="sticker vuepress-toc"><div class="vuepress-toc-item vuepress-toc-h2 active"><a href="#introduction" title="Introduction">Introduction</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#basic-plan" title="Basic Plan">Basic Plan</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#ansible-intro" title="Ansible Intro">Ansible Intro</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#network-pre-configuration" title="Network Pre-Configuration">Network Pre-Configuration</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#building-vms" title="Building VMs">Building VMs</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#configuring-ansible-inventory" title="Configuring Ansible Inventory">Configuring Ansible Inventory</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#basic-setup" title="Basic Setup">Basic Setup</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#create-the-proxmox-resource-pool" title="Create the Proxmox resource pool">Create the Proxmox resource pool</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#download-the-debian-vm-image" title="Download the Debian VM image">Download the Debian VM image</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#copy-local-ssh-key-to-the-proxmox-server" title="Copy local SSH key to the Proxmox server">Copy local SSH key to the Proxmox server</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#create-the-vms" title="Create the VMs">Create the VMs</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#import-the-debian-disk-to-each-vm" title="Import the Debian disk to each VM">Import the Debian disk to each VM</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#configure-the-imported-disks" title="Configure the imported disks">Configure the imported disks</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#resize-the-hard-disks" title="Resize the hard disks">Resize the hard disks</a></div><div class="vuepress-toc-item vuepress-toc-h3"><a href="#finally-start-the-vms-and-wait-for-them-to-be-available" title="Finally, start the VMs and wait for them to be available">Finally, start the VMs and wait for them to be available</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#run-the-playbook" title="Run the playbook">Run the playbook</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#next-time" title="Next Time">Next Time</a></div><div class="vuepress-toc-item vuepress-toc-h2"><a href="#references" title="References">References</a></div></div></div></div> <footer class="footer" data-v-fdbf4940><div class="footer-left-wrap" data-v-fdbf4940><ul class="contact" data-v-fdbf4940><li class="contact-item" data-v-fdbf4940><a href="https://github.com/mlaustin44" target="_blank" rel="noopener noreferrer" class="nav-link external" data-v-fdbf4940><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github" data-v-fdbf4940><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" data-v-fdbf4940></path></svg>
          
        </a></li></ul></div> <div class="footer-right-wrap" data-v-fdbf4940><ul class="copyright" data-v-fdbf4940><li class="copyright-item" data-v-fdbf4940><a href="/2020/08/09/promox-k8s-part-1-vms/.html" class="nav-link" data-v-fdbf4940>Matthew Austin © 2020</a></li></ul></div></footer></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.719779a0.js" defer></script><script src="/assets/js/6.5a5d3722.js" defer></script><script src="/assets/js/3.0200f067.js" defer></script><script src="/assets/js/9.076c7963.js" defer></script>
  </body>
</html>
